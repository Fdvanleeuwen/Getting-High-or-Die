---
title: "Clean_doc"
author: "Florian van Leeuwen"
date: "10/26/2022"
output: html_document
---

--- title page ---
--- add the tabs ---

```{r, warning = F, message = F}
library(readr)
library(tidyverse)
library(psych)
library(MASS)
library(pROC)
library(randomForest)
library(xgboost)
library(rpart)
library(rpart.plot)
library(jtools)
library(class)
library(ISLR)
library(Matrix)
```

## Tidy the data

```{r}
# import data
data<- read.csv("mushrooms.csv")
```

```{r}
# tidy data -- merge redundant categories 
mushrooms <- data %>% 
    mutate(across(where(is.character), as_factor))%>%
    dplyr::select(-veil.type, -stalk.root)%>%     
    mutate(cap.shape = cap.shape %>% 
             fct_recode("bell"    = "b",
                        "conical" = "c",
                        "convex"  = "x",
                        "flat"    = "f", 
                        "knobbed" = "k",
                        "sunken"  = "s"),
           cap.surface = cap.surface %>% 
             fct_recode("fibrous" = "f",
                        "grooves" = "g",
                        "scaly"   = "y",
                        "smooth"  = "s"), 
           bruises = bruises %>% 
             fct_recode("true"       = "t",
                        "false"      = "f"), 
           odor = odor %>%
             fct_recode("almond"     = "a",
                        "anise"      = "l",
                        "creosote"   = "c",
                        "fishy"      = "y",
                        "foul"       = "f",
                        "musty"      = "m",
                        "none"       = "n",
                        "pungent"    = "p",
                        "spicy"      = "s"),
           cap.color = cap.color %>%                 
             fct_recode("brown"      = "n",
                        "brown"      = "b",
                        "brown"      = "c", 
                        "pink"       = "u",                      
                        "pink"       = "e", 
                        "pink"       = "p", 
                        "gray"       = "g",
                        "green"      = "r", 
                        "white"      = "w",
                        "yellow"     = "y"),
           gill.attachment = gill.attachment %>% 
             fct_recode("attached"   = "a",
                        "free"       = "f"), 
           gill.spacing = gill.spacing %>% 
             fct_recode("close"      = "c",
                        "crowded"    = "w"),
           gill.size = gill.size %>% 
             fct_recode("broad"      = "b",
                        "narrow"     = "n"), 
           gill.color = gill.color %>% 
             fct_recode("black"      ="k",
                        "brown"      ="n",
                        "brown"      ="b",
                        "brown"      ="h",
                        "gray"       ="g", 
                        "green"      ="r",
                        "orange"     ="o",
                        "pink"       ="p",
                        "pink"       ="u",
                        "pink"       ="e",
                        "white"      ="w",
                        "yellow"     ="y"),
           stalk.shape = stalk.shape %>% 
             fct_recode("enlarging"  ="e",
                        "tapering"   ="t"), 
           stalk.surface.above.ring = stalk.surface.above.ring %>% 
             fct_recode("fibrous"    ="f",
                        "scaly"      ="y",
                        "silky"      ="k",
                        "smooth"     ="s"), 
          stalk.surface.below.ring = stalk.surface.below.ring %>% 
             fct_recode("fibrous"    ="f",
                        "scaly"      ="y",
                        "silky"      ="k",
                        "smooth"     ="s"), 
          stalk.color.above.ring = stalk.color.above.ring %>% 
            fct_recode("brown"       ="n",
                       "brown"       ="b",
                       "brown"       ="c",
                       "gray"        ="g",
                       "orange"      ="o",
                       "pink"        ="p",
                       "pink"        ="e",
                       "white"       ="w",
                       "yellow"      ="y",), 
          stalk.color.below.ring = stalk.color.below.ring %>% 
            fct_recode("brown"       ="n",
                       "brown"       ="b",
                       "brown"       ="c",
                       "gray"        ="g",
                       "orange"      ="o",
                       "pink"        ="p",
                       "pink"        ="e",
                       "white"       ="w",
                       "yellow"      ="y",), 
          veil.color = veil.color %>%
            fct_recode("brown"       ="n",
                       "orange"      ="o",
                       "white"       ="w",
                       "yellow"      ="y"),
          ring.number = ring.number %>% 
            fct_recode("none"        ="n",
                       "one"         ="o",
                       "two"         ="t"), 
          ring.type = ring.type %>% 
            fct_recode("evanescent"  ="e",
                       "flaring"     ="f",
                       "large"       ="l",
                       "none"        ="n",
                       "pendant"     ="p"),
          spore.print.color = spore.print.color %>% 
            fct_recode("black"   ="k",
                       "brown"   ="n",
                       "brown"   ="b",
                       "brown"   ="h",
                       "green"   ="r",
                       "orange"  ="o",
                       "purple"  ="u",
                       "white"   ="w",
                       "yellow"  ="y"), 
         population = population %>% 
           fct_recode("group"    ="a",
                      "group"    ="c",
                      "group"    ="n",
                      "group"    ="s",
                      "group"    ="v",
                      "solitary" ="y"), 
         habitat = habitat %>% 
           fct_recode("grasses"  ="g",
                      "woods"    ="l",
                      "grasses"  ="m",
                      "urban"    ="p",
                      "urban"    ="u",
                      "waste"    ="w",
                      "woods"    ="d"))
```

```{r} 
# set seed 
set.seed(191)

# test and train
n = dim(mushrooms)[1]
mushrooms_split <- mushrooms %>% 
                   mutate(split = sample(rep(c("train", "test"), 
                                             times = c(round(.8*n), round(.2*n)))))

mushrooms_train <- mushrooms_split %>% 
                  filter(split == "train") %>%
                  dplyr::select(-split)

mushrooms_test  <- mushrooms_split %>% 
                  filter(split == "test") %>%
                  dplyr::select(-split)
```

```{r}
# beginner 
beginner       <- mushrooms %>% 
                  dplyr::select(class, cap.shape, cap.color, bruises, gill.color, 
                                stalk.shape, ring.number, population, habitat)

beginner_train <- mushrooms_train %>% 
                  dplyr::select(class, cap.shape, cap.color, bruises, gill.color, 
                                stalk.shape, ring.number, population, habitat)

beginner_test  <- mushrooms_test %>% 
                  dplyr::select(class, cap.shape, cap.color, bruises, gill.color,
                                stalk.shape, ring.number, population, habitat)
```

## Logistic regression

### Generating all possible combination of predictors

```{r}
generate_formulas <- function(p, x_vars, y_var) {
  x_vars <- colnames(x_vars)
  # Input checking
  if (p %% 1 != 0)           stop("Input an integer n")
  if (p > length(x_vars))    stop("p should be smaller than number of vars")
  if (!is.character(x_vars)) stop("x_vars should be a character vector")
  if (!is.character(y_var))  stop("y_vars should be character type")
  
  # combn generates all combinations, apply turns them into formula strings
  apply(combn(x_vars, p), 2, function(vars) {
    paste0(y_var, " ~ ", paste(vars, collapse = " + "))
  })
}
```

## Function to find best predictors and best alpha based on chosen metric (Balance from sens and spec with more weight for sens)

```{r}
# this formula should not be used for itself, but just in combination with the cross validation formula for finding the best predictors
find_best_predictors <- function(formulas,train,valid, valid_y){
  
  out <-data.frame(matrix(nrow = length(formulas), ncol = 3))
  thres <- data.frame(seq(0.05,0.95,length.out=19))
  alpha <- seq(0.05,0.95,length.out=19)

  for(i in 1:length(formulas)){
    model <- glm(formulas[i], family=binomial, data=train)
    pred_prob <- predict(model, type = "response", newdata = valid)
    
    comb <- data.frame(matrix(nrow = nrow(thres), ncol = 3))
    comb$alpha <- alpha
    colnames(comb) <- c("TPR", "TNR","mean","alpha")
      
    for(j in 1:nrow(thres)){
      pred_lr <- c()
      pred_lr <- case_when(pred_prob > as.numeric(thres[j,1]) ~ 1, pred_prob <= as.numeric(thres[j,1]) ~ 0)
      cmat_lr <- table(true = valid_y, predicted = pred_lr)
      if(sum(pred_lr == 1 ) == length(valid_y)){
        TN <- cmat_lr[1, 1]
        FN <- cmat_lr[2, 1]
        FP <- 0
        TP <- 0
      }
      else if(sum(pred_lr == 0 ) == length(valid_y)){
        TN <- 0
        FN <- 0
        FP <- cmat_lr[1, 1]
        TP <- cmat_lr[2, 1]
      }      else{
        TN <- cmat_lr[1, 1]
        FN <- cmat_lr[2, 1]
        FP <- cmat_lr[1, 2]
        TP <- cmat_lr[2, 2]
      }
      comb[j,1] <- TP / (TP + FN)
      comb[j,2] <- 1- (FP / (TN + FP)) # Same as TNR just to emphasize
      comb[j,3] <- (comb[j,1]+comb[j,2]*1.5)/2
      }
    comb <- comb[order(comb$mean, decreasing=T),]
    
    out[i,1] <- comb[1,3]
    out[i,2] <- formulas[i]
    out[i,3] <- comb[1,4]
    
    }
  colnames(out) <- c("meanTPR_TNR", "formula","alpha")
  
return(out)
}
```


### Cross-validating the choice of predictors
```{r}
cv_best_pred <- function(k, dataset, form, top){
  
  Y <- data.frame(matrix(nrow = length(form), ncol = k))
  Z <- data.frame(matrix(nrow = length(form), ncol = k))
  Final <- data.frame(matrix(nrow = length(form), ncol = 3))
  
  # first, add a selection column to the dataset as before
  n_samples  <- nrow(dataset)
  select_vec <- rep(1:k, length.out = n_samples)
  data_split <- dataset %>% mutate(folds = sample(select_vec))
  
  for (i in 1:k) {
    # split the data in train and validation set
    data_train <- data_split %>% filter(folds != i)
    data_valid <- data_split %>% filter(folds == i)
    
    data_valid_y <- data_valid$class
    
    X <- find_best_predictors(formulas=form,train=data_train,valid=data_valid,valid_y=data_valid_y)
    Y[,i] <- X$meanTPR_TNR
    Z[,i] <- X$alpha
  }
  Final[,1]  <- X[[2]]
  Final[,2] <- rowMeans(Y)
  Final[,3] <- rowMeans(Z)
  Final <- Final[order(Final[2],decreasing = T),]
  
  colnames(Final) <- c("Formula", "CV_Mean of TNR_TPR"," CV_alpha")
  return(Final[1:top,])
}

```

### Cross validating the chosen model and compare it to other models
```{r}
cv_best_models <- function(k, dataset, form, alpha, seed){
  
  set.seed(seed)
  
  comb <- data.frame(matrix(nrow = k, ncol = 3))
  colnames(comb) <- c("TPR", "TNR","Metric")
  Final <- data.frame(matrix(nrow = length(form), ncol = 3))
  
  # first, add a selection column to the dataset as before
  n_samples  <- nrow(dataset)
  select_vec <- rep(1:k, length.out = n_samples)
  data_split <- dataset %>% mutate(folds = sample(select_vec))
  
  for (i in 1:k) {
    # split the data in train and validation set
    data_train <- data_split %>% filter(folds != i)
    data_valid <- data_split %>% filter(folds == i)
    
    data_valid_y <- data_valid$class
    
    model <- glm(form, family=binomial, data= data_train)
    pred_prob <- predict(model, type = "response", newdata = data_valid)
    pred_lr <- ifelse(pred_prob > as.numeric(alpha), 1,0)
    cmat_lr <- table(true = data_valid_y, predicted = pred_lr)
    
    TN <- cmat_lr[1, 1]
    FN <- cmat_lr[2, 1]
    FP <- cmat_lr[1, 2]
    TP <- cmat_lr[2, 2]
    
    comb[i,1] <- TP / (TP + FN)
    comb[i,2] <- TN / (TN + FP)
    comb[i,3] <- (comb[i,2]*1.5+comb[i,1])/2
  }
  Final[,1]  <- mean(comb[,1])
  Final[,2] <- mean(comb[,2])
  Final[,3] <- mean(comb[,3])
  
  colnames(Final) <- c("CV_TPR", "CV_TNR","CV_Metric")
  
  return(Final)
}
```

### Training Set results from the chosen models
```{r}
test_metric <- function(formula, train, test,alpha){
  fit1 <- glm(formula, family=binomial, data=train)
  pred_prob <- predict(fit1, type = "response", newdata = test)
  pred_lr   <- ifelse(pred_prob > as.numeric(alpha), 1,0)
  confm <- table(true = test$class, predicted = pred_lr)
  Spec <- confm[2, 2] / (confm[2, 2] + confm[2, 1])
  Sens <- confm[1, 1] / (confm[1, 1] + confm[1, 2])
  Metric <- (Sens*1.5+Spec)/2
  return(list(matrix=confm, Specificty=Spec, Sensitivity=Sens, Metric=Metric))
}
```

### Applying the formulas
```{r}
mushrooms_begin_x <- beginner %>%
  dplyr::select(-class)
```

```{r}
# Generating the combination of formulas
formulas_2 <- generate_formulas(p=2,x_vars=mushrooms_begin_x, y_var="class")
formulas_3 <- generate_formulas(p=3,x_vars=mushrooms_begin_x, y_var="class")
formulas_4 <- generate_formulas(p=4,x_vars=mushrooms_begin_x, y_var="class")
formulas_5 <- generate_formulas(p=5,x_vars=mushrooms_begin_x, y_var="class")
formulas_6 <- generate_formulas(p=6,x_vars=mushrooms_begin_x, y_var="class")
```


```{r}
# generating the cross-validated results for the best choice of predictors
pred2 <- cv_best_pred(5, beginner_train, formulas_2, 5)
pred3 <- cv_best_pred(5, beginner_train, formulas_3, 5)
pred4 <- cv_best_pred(5, beginner_train, formulas_4, 5)
pred5 <- cv_best_pred(5, beginner_train, formulas_5, 5)
pred6 <- cv_best_pred(5, beginner_train, formulas_6, 5)
```

```{r}
# comparing the results 
mean(pred2[,2])
mean(pred3[,2])
mean(pred4[,2])
mean(pred5[,2])
mean(pred6[,2])
# not a huge improvement between 3, 4, and 5
# All of these models would yield good results
```

```{r}
# comparison between models
cv_best_models(5, beginner_train, pred4[1,1], pred4[1,3], 123)
cv_best_models(5, beginner_train, pred5[1,1], pred5[1,3], 124)
cv_best_models(5, beginner_train, pred6[1,1], pred6[1,3], 125)
```

```{r}
# comparison within models
cv_best_models(5, beginner_train, pred5[1,1], pred5[1,3], 123) # sticking with this model 
cv_best_models(5, beginner_train, pred5[2,1], pred5[2,3], 124)
cv_best_models(5, beginner_train, pred5[3,1], pred5[3,3], 125)
```

```{r}
# assessing test set predictions
test_metric(pred5[1,1], beginner_train, beginner_test,pred5[1,3]) 
test_metric(pred5[2,1], beginner_train, beginner_test,pred5[2,3])

test_metric(pred6[1,1], beginner_train, beginner_test,pred6[1,3]) # this model performs slightly better in the direction we want as it has less False false negatives, comapred to 5, but also only marginally
test_metric(pred6[2,1], beginner_train, beginner_test,pred6[2,3])
```

### Starting argumention for our decision making

One more thought: We might want to play around with different wights for the Sensitivity (not too much difference when I tried with 1.2 and 1.5), feel free to do so
- More things to do: Think about evaluation methods between the tree based and the regression based method


- Our goal is to make it very easy for beginners to see if mushrooms are edible or poisonous. For this reason we are mainly interested in a dimension reduction where we try to have the least amount of predictors which still yield good results. On top of that, are we mainly interested in classifying mushrooms which are actually poisonous as poisonous. That means avoiding to have a lot of false negatives (mushrooms which are actually poisnous, but are classified as edible). For this sake we are even willing to missclassify more mushrooms which are actually edible as poisonous.

- In this regard we opted to choose our own metric based on a balance of specificity and sensitivity, where we give more weight to the sensitivity as this should decrease the false negative rate. Moreover, we apply cross validation in multiple steps so our choice of predictors and also our model comparison is not depending on chance. 

- Finally, we compare the test set metrics (Sens, Spec, and our own Metric) between the different possible models and try to give advise for how to proceed when encountering a mushroom somewhere. 




