---
title: "Supervised Learning and Visualisation: Assignment 2"
author: "Group 1: Florian van Leeuwen, AlexCarriero, Christoph Voltzke, Judith Neve"
date: "13/11/2022"
output: html_document
---

---

--- title page --- how do we do this?? there's not multiple pages on html
--- add the tabs --- shannon pls help us

```{r setup, echo=FALSE}
library(knitr)
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE,
  echo = FALSE
)
```

```{r libraries}
library(readr)
library(tidyverse)
library(psych)
library(MASS)
library(pROC)
library(randomForest)
library(xgboost)
library(rpart)
library(rpart.plot)
library(jtools)
library(class)
library(ISLR)
library(Matrix)
library(kableExtra)
```

## Introduction

The focus of this project is the accurate classification of mushrooms as edible or poisonous using an [open dataset from Kaggle](https://www.kaggle.com/datasets/uciml/mushroom-classification). The end goal is to develop an app for mushroom foragers of all levels, that will reliably classify a mushroom as edible or poisonous. In this project, we develop the classification algorithms that will be used within this app. We predict whether a mushroom is edible, that is, the given probabilities are the probability that a mushroom is edible.\
\
The dataset contains 8124 observations of 22 variables (plus the class). All variables are categorical and describe various characteristics of mushrooms, detailed in Table 1. These characteristics range from easily understandable (e.g., cap colour) to senseless for people unfamiliar with mushrooms (e.g., stalk root). In order for our app to be usable by all, we reduce the number of variables in order to only include the most easily understandable variables. Furthermore, we reduce the number of options for some of these variables by grouping certain categories together in order to limit misspecification of predictors (e.g., brown and buff will be both called brown).\
\
We will first develop models using only this reduced set of predictors; if model performance is unsatisfactory, we will consider some further models that include more predictors.

```{r import data}
# import data
mushrooms <- read.csv("mushrooms.csv")
```

```{r tidy data}
# tidy data -- merge redundant categories 
mushrooms <- mushrooms %>% 
    mutate(across(where(is.character), as_factor))%>%
    dplyr::select(-veil.type, -stalk.root)%>%     
    mutate(cap.shape = cap.shape %>% 
             fct_recode("bell"    = "b",
                        "conical" = "c",
                        "convex"  = "x",
                        "flat"    = "f", 
                        "knobbed" = "k",
                        "sunken"  = "s"),
           cap.surface = cap.surface %>% 
             fct_recode("fibrous" = "f",
                        "grooves" = "g",
                        "scaly"   = "y",
                        "smooth"  = "s"), 
           bruises = bruises %>% 
             fct_recode("true"       = "t",
                        "false"      = "f"), 
           odor = odor %>%
             fct_recode("almond"     = "a",
                        "anise"      = "l",
                        "creosote"   = "c",
                        "fishy"      = "y",
                        "foul"       = "f",
                        "musty"      = "m",
                        "none"       = "n",
                        "pungent"    = "p",
                        "spicy"      = "s"),
           cap.color = cap.color %>%                 
             fct_recode("brown"      = "n",
                        "brown"      = "b",
                        "brown"      = "c", 
                        "pink"       = "u",                      
                        "pink"       = "e", 
                        "pink"       = "p", 
                        "gray"       = "g",
                        "green"      = "r", 
                        "white"      = "w",
                        "yellow"     = "y"),
           gill.attachment = gill.attachment %>% 
             fct_recode("attached"   = "a",
                        "free"       = "f"), 
           gill.spacing = gill.spacing %>% 
             fct_recode("close"      = "c",
                        "crowded"    = "w"),
           gill.size = gill.size %>% 
             fct_recode("broad"      = "b",
                        "narrow"     = "n"), 
           gill.color = gill.color %>% 
             fct_recode("black"      ="k",
                        "brown"      ="n",
                        "brown"      ="b",
                        "brown"      ="h",
                        "gray"       ="g", 
                        "green"      ="r",
                        "orange"     ="o",
                        "pink"       ="p",
                        "pink"       ="u",
                        "pink"       ="e",
                        "white"      ="w",
                        "yellow"     ="y"),
           stalk.shape = stalk.shape %>% 
             fct_recode("enlarging"  ="e",
                        "tapering"   ="t"), 
           stalk.surface.above.ring = stalk.surface.above.ring %>% 
             fct_recode("fibrous"    ="f",
                        "scaly"      ="y",
                        "silky"      ="k",
                        "smooth"     ="s"), 
          stalk.surface.below.ring = stalk.surface.below.ring %>% 
             fct_recode("fibrous"    ="f",
                        "scaly"      ="y",
                        "silky"      ="k",
                        "smooth"     ="s"), 
          stalk.color.above.ring = stalk.color.above.ring %>% 
            fct_recode("brown"       ="n",
                       "brown"       ="b",
                       "brown"       ="c",
                       "gray"        ="g",
                       "orange"      ="o",
                       "pink"        ="p",
                       "pink"        ="e",
                       "white"       ="w",
                       "yellow"      ="y",), 
          stalk.color.below.ring = stalk.color.below.ring %>% 
            fct_recode("brown"       ="n",
                       "brown"       ="b",
                       "brown"       ="c",
                       "gray"        ="g",
                       "orange"      ="o",
                       "pink"        ="p",
                       "pink"        ="e",
                       "white"       ="w",
                       "yellow"      ="y",), 
          veil.color = veil.color %>%
            fct_recode("brown"       ="n",
                       "orange"      ="o",
                       "white"       ="w",
                       "yellow"      ="y"),
          ring.number = ring.number %>% 
            fct_recode("none"        ="n",
                       "one"         ="o",
                       "two"         ="t"), 
          ring.type = ring.type %>% 
            fct_recode("evanescent"  ="e",
                       "flaring"     ="f",
                       "large"       ="l",
                       "none"        ="n",
                       "pendant"     ="p"),
          spore.print.color = spore.print.color %>% 
            fct_recode("black"   ="k",
                       "brown"   ="n",
                       "brown"   ="b",
                       "brown"   ="h",
                       "green"   ="r",
                       "orange"  ="o",
                       "purple"  ="u",
                       "white"   ="w",
                       "yellow"  ="y"), 
         population = population %>% 
           fct_recode("group"    ="a",
                      "group"    ="c",
                      "group"    ="n",
                      "group"    ="s",
                      "group"    ="v",
                      "solitary" ="y"), 
         habitat = habitat %>% 
           fct_recode("grasses"  ="g",
                      "woods"    ="l",
                      "grasses"  ="m",
                      "urban"    ="p",
                      "urban"    ="u",
                      "waste"    ="w",
                      "woods"    ="d"),
         class = ifelse(class == "e", 1, 0))
```

```{r}
table1 <- tibble(
  Variable = c(
    "cap shape",
    "cap surface",
    "cap color",
    "bruises",
    "odor",
    "gill attachment",
    "gill spacing",
    "gill size",
    "gill color",
    "stalk shape",
    "stalk root",
    "stalk surface above ring",
    "stalk surface below ring",
    "stalk color above ring",
    "stalk color below ring",
    "veil type",
    "veil color",
    "ring number",
    "ring type",
    "spore print color",
    "population",
    "habitat"
  ),
  `Original levels` = c(
    "bell, conical, convex, flat, knobbed, sunken",
    "fibrous, grooves, scaly, smooth",
    "brown, buff, cinnamon, gray, green, pink, purple, red, white, yellow",
    "yes, no",
    "almond, anise, creosote, fishy, foul, musty, none, pungent, spicy",
    "attached, descending, free, notched",
    "close, crowded, distant",
    "broad, narrow",
    "black, brown, buff, chocolate, gray, green, orange, pink, purple, red, white, yellow",
    "enlarging, tapering",
    "bulbous, club, cup, equal, rhizomorphs, rooted, missing",
    "fibrous, scaly, silky, smooth",
    "fibrous, scaly, silky, smooth",
    "brown, buff, cinnamon, gray, orange, pink, red, white, yellow",
    "brown, buff, cinnamon, gray, orange, pink, red, white, yellow",
    "partial, universal",
    "brown, orange, white, yellow",
    "none, one, two",
    "cobwebby, evanescent, flaring, large, none, pendant, sheathing, zone",
    "black, brown, buff, chocolate, green, orange, purple, white, yellow",
    "abundant, clustered, numerous, scattered, several, solitary",
    "grasses, leaves, meadows, paths, urban, waste, woods"
  ),
  `Included levels` = c(
    "bell, conical, convex, flat, knobbed, sunken",
    "-",
    "brown (includes brown, buff, cinnamon), gray, green, pink (includes pink, purple, red), white, yellow",
    "yes, no",
    "-",
    "-",
    "-",
    "-",
    "black, brown (includes brown, buff, chocolate), gray, green, orange, pink (includes pink, purple, red), white, yellow",
    "enlarging, tapering",
    "-",
    "-",
    "-",
    "-",
    "-",
    "-",
    "-",
    "none, one, two",
    "-",
    "-",
    "group, solitary",
    "grasses (includes grasses, meadows), woods (includes woods, leaves), urban (includes paths, urban), waste"
  )
)

table1 %>%
  kbl(format = "html", caption = "Table 1. Predictors in the dataset.") %>% 
  kable_styling("striped") 
```

## Methods

We split the dataset into a training dataset, which will be used to fit the candidate models, and a testing dataset, which will be used to evaluate and compare the models. The training dataset contains 80% of the observations in the full dataset. All models will be evaluated using something something (metrics & justification)

```{r test and train} 
# set seed 
set.seed(191)

# test and train
n <- nrow(mushrooms)
mushrooms_split <- mushrooms %>% 
                   mutate(split = sample(rep(c("train", "test"), 
                                             times = c(round(.8*n), round(.2*n)))))

mushrooms_train <- mushrooms_split %>% 
                  filter(split == "train") %>%
                  dplyr::select(-split)

mushrooms_test  <- mushrooms_split %>% 
                  filter(split == "test") %>%
                  dplyr::select(-split)
```

```{r}
# beginner 
beginner       <- mushrooms %>% 
                  dplyr::select(class, cap.shape, cap.color, bruises, gill.color, 
                                stalk.shape, ring.number, population, habitat)

beginner_train <- mushrooms_train %>% 
                  dplyr::select(class, cap.shape, cap.color, bruises, gill.color, 
                                stalk.shape, ring.number, population, habitat)

beginner_test  <- mushrooms_test %>% 
                  dplyr::select(class, cap.shape, cap.color, bruises, gill.color,
                                stalk.shape, ring.number, population, habitat)
                

# advanced 
advanced       <- mushrooms 
advanced_train <- mushrooms_train
advanced_test  <- mushrooms_test
```

```{r}
rm(data, mushrooms, mushrooms_split, mushrooms_test, mushrooms_train)
```


### Logistic regression

something something, what are we doing and why, what are we comparing, how are we making a simple model more complex

#### Formulas

```{r}
generate_formulas <- function(p, x_vars, y_var) {
  x_vars <- colnames(x_vars)
  # Input checking
  if (p %% 1 != 0)           stop("Input an integer n")
  if (p > length(x_vars))    stop("p should be smaller than number of vars")
  if (!is.character(x_vars)) stop("x_vars should be a character vector")
  if (!is.character(y_var))  stop("y_vars should be character type")
  
  # combn generates all combinations, apply turns them into formula strings
  apply(combn(x_vars, p), 2, function(vars) {
    paste0(y_var, " ~ ", paste(vars, collapse = " + "))
  })
}
```

```{r}
find_best_predictors <- function(formulas,train,valid, valid_y){
  
  out <-data.frame(matrix(nrow = length(formulas), ncol = 2))
  thres <- data.frame(seq(0.05,0.95,length.out=19))
  alpha <- seq(0.05,0.95,length.out=19)

  for(i in 1:length(formulas)){
    model <- glm(formulas[i], family=binomial, data=train)
    pred_prob <- predict(model, type = "response", newdata = valid)
    
    comb <- data.frame(matrix(nrow = nrow(thres), ncol = 3))
    comb$alpha <- alpha
    colnames(comb) <- c("TPR", "TNR","mean","alpha")
      
    for(j in 1:nrow(thres)){
      pred_lr <- c()
      pred_lr <- case_when(pred_prob > as.numeric(thres[j,1]) ~ "Yes", pred_prob <= as.numeric(thres[j,1]) ~ "No")
      cmat_lr <- table(true = valid_y, predicted = pred_lr)
      if(sum(pred_lr == "Yes" ) == nrow(beginner_test)){
        TN <- cmat_lr[1, 1]
        FN <- cmat_lr[2, 1]
        FP <- 0
        TP <- 0
      }
      else if(sum(pred_lr == "No" ) == nrow(beginner_test)){
        TN <- 0
        FN <- 0
        FP <- cmat_lr[1, 1]
        TP <- cmat_lr[2, 1]
      }      else{
        TN <- cmat_lr[1, 1]
        FN <- cmat_lr[2, 1]
        FP <- cmat_lr[1, 2]
        TP <- cmat_lr[2, 2]
      }
      comb[j,1] <- TP / (TP + FN)
      comb[j,2] <- TN / (TN + FP)
      comb[j,3] <- (comb[j,1]*1.2+comb[j,2])/2
      }
    comb <- comb[order(comb$mean, decreasing=T),]
    
    out[i,1] <- comb[1,3]
    out[i,2] <- formulas[i]
    
    }
  colnames(out) <- c("meanTPR_TNR", "formula")
  out <- out[order(out$meanTPR_TNR,decreasing = T),]
  
return(best=out[1:3, ])
}
```

```{r}
# alternative
best_model <- function(formulas,train,valid, valid_y){
  out <-data.frame(matrix(nrow = length(formulas), ncol = 2))
  
  for(i in 1:length(formulas)){
    model <- glm(formulas[i], family=binomial, data=train)
    pred_prob <- predict(model, type = "response", newdata = valid)
    roc_lr1 <- roc(valid_y, pred_prob)
    out[i,1] <- roc_lr1$auc[1]
    out[i,2] <- formulas[i]
    }
  colnames(out) <- c("auc", "formula")
  out <- out[order(out$auc,decreasing = T),]
  
return(best=out[1:3, ])
}
```

```{r}
mushrooms_begin_x <- beginner %>%
  dplyr::select(-class)
```

```{r}
set.seed(14)
```

```{r}
formulas_2 <- generate_formulas(p=2,x_vars=mushrooms_begin_x, y_var="class")
formulas_3 <- generate_formulas(p=3,x_vars=mushrooms_begin_x, y_var="class")
formulas_4 <- generate_formulas(p=4,x_vars=mushrooms_begin_x, y_var="class")
formulas_5 <- generate_formulas(p=5,x_vars=mushrooms_begin_x, y_var="class")
formulas_6 <- generate_formulas(p=6,x_vars=mushrooms_begin_x, y_var="class")
```

```{r}
pred2 <- find_best_predictors(formulas=formulas_2,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred3 <- find_best_predictors(formulas=formulas_3,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred4 <- find_best_predictors(formulas=formulas_4,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred5 <- find_best_predictors(formulas=formulas_5,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred6 <- find_best_predictors(formulas=formulas_6,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)

```


```{r, echo=FALSE}
pred2_b <- best_model(formulas=formulas_2,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred3_b <- best_model(formulas=formulas_3,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred4_b <- best_model(formulas=formulas_4,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred5_b <- best_model(formulas=formulas_5,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
pred6_b <- best_model(formulas=formulas_6,train=beginner_train,valid=beginner_test,valid_y=beginner_test$class)
```

### Trees

something something, what are we doing and why and how are we making it more complex

```{r}

```

## Results

something something about the performance of each model

compare the logistic regressions with each other
compare the trees with each other

do we need to do any advanced model (no these are good)

## Discussion

pros and cons of regression and trees, which one we want to use
